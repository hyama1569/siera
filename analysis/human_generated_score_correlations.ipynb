{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ArHXH0tDu11"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/Colab Notebooks/master_thesis\n",
        "!pip install git+https://github.com/feralvam/easse.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "beFXe0z9IbmO",
        "outputId": "5a543be1-91d2-49b8-f6db-ebfeb06d3a61"
      },
      "outputs": [],
      "source": [
        "import easse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yKvZwJpl9Xt",
        "outputId": "05b8cf6a-6df1-4eec-acdf-03906858c1cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python38.zip',\n",
              " '/usr/lib/python3.8',\n",
              " '/usr/lib/python3.8/lib-dynload',\n",
              " '',\n",
              " '/usr/local/lib/python3.8/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.8/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmdyTce9Ve6D",
        "outputId": "f3177789-1011-4c3e-f906-16b6dcb723c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHJyRIXDDdVZ"
      },
      "outputs": [],
      "source": [
        "#!pip install pingouin\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import pingouin as pg\n",
        "from scipy.stats import zscore, spearmanr, pearsonr\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4czzz_3CHC9m",
        "outputId": "51f06489-d743-4e3e-e866-a02213598931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f9c72e63fa0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import en_core_web_sm\n",
        "en_core_web_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjcSF_2wDefF"
      },
      "outputs": [],
      "source": [
        "#import en_core_web_md\n",
        "#en_core_web_md.load()\n",
        "import spacy\n",
        "spacy.cli.download('en_core_web_md')\n",
        "spacy.load('en_core_web_md')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeVNZJF3Y-hy"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o56yqgkhpoay"
      },
      "outputs": [],
      "source": [
        "# From https://github.com/feralvam/metaeval-simplification/blob/main/notebooks/correlation.py\n",
        "from itertools import combinations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore, pearsonr, t\n",
        "from scipy.stats.mstats import mquantiles\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import sys\n",
        "\n",
        "\n",
        "def _standardise_ratings(df, rater_id_cols, aspect_col):\n",
        "    return df.groupby(rater_id_cols)[aspect_col].transform(lambda x: zscore(x))\n",
        "\n",
        "\n",
        "def _simulate_two_annotators(ratings, num_ratings_annotatorA=1):\n",
        "    ratings_shuffled = np.random.permutation(ratings)\n",
        "    ratingA = np.mean(ratings_shuffled[:num_ratings_annotatorA])\n",
        "    ratingB = np.mean(ratings_shuffled[num_ratings_annotatorA:])\n",
        "    return [ratingA, ratingB]\n",
        "\n",
        "\n",
        "def compute_inter_annotator_agreement(df_ratings, segment_id_cols, rater_id_cols, aspects,\n",
        "                                      n_bins=5, use_quantiles=True, n_simulations=1000):\n",
        "    iaa_per_aspect = {}\n",
        "    for aspect in aspects:\n",
        "        if f\"{aspect}_zscore\" not in df_ratings.columns:\n",
        "            df_ratings[f\"{aspect}_zscore\"] = _standardise_ratings(df_ratings, rater_id_cols, aspect)\n",
        "        df_scores = df_ratings[segment_id_cols + [f'{aspect}_zscore']]\n",
        "        # Bin the data in n_bins\n",
        "        if use_quantiles:  # equally-distributed\n",
        "            _, bins_ranges = pd.qcut(df_scores[f'{aspect}_zscore'], q=n_bins, retbins=True)\n",
        "        else:  # equally-spaced\n",
        "            _, bins_ranges = pd.cut(df_scores[f'{aspect}_zscore'], bins=n_bins, retbins=True)\n",
        "        kappa_values = []\n",
        "        for _ in tqdm(range(n_simulations)):\n",
        "            ratings_simulation = df_scores.groupby(segment_id_cols)[f'{aspect}_zscore'].apply(_simulate_two_annotators).to_list()\n",
        "            raterA, raterB = zip(*ratings_simulation)\n",
        "            kappa_values.append(cohen_kappa_score(np.digitize(raterA, bins_ranges), np.digitize(raterB, bins_ranges), weights='quadratic'))\n",
        "        iaa_per_aspect[aspect] = (np.mean(kappa_values), np.std(kappa_values))\n",
        "    return iaa_per_aspect\n",
        "\n",
        "\n",
        "def compute_segment_scores(df_ratings, segment_id_cols, rater_id_cols, aspects):\n",
        "    scores_cols = []\n",
        "    for aspect in aspects:\n",
        "        df_ratings[f\"{aspect}_zscore\"] = _standardise_ratings(df_ratings, rater_id_cols, aspect)\n",
        "        scores_cols += [aspect, f\"{aspect}_zscore\"]\n",
        "    df_segment_scores = df_ratings.groupby(segment_id_cols)[scores_cols].agg([np.mean])\n",
        "    df_segment_scores.columns = [a for a, _ in df_segment_scores.columns]\n",
        "\n",
        "    return df_segment_scores\n",
        "\n",
        "\n",
        "def _select_pairs_in_group(group, min_score_difference=0):\n",
        "    data = []\n",
        "    for (system_a, score_a, zscore_a), (system_b, score_b, zscore_b) in combinations(group.values, 2):\n",
        "        # select the pair if its absolute difference in DA scores is greater than 25\n",
        "        if abs(score_a - score_b) > min_score_difference:\n",
        "            data.append([system_a, score_a, zscore_a, system_b, score_b, zscore_b])\n",
        "    df_selected_pairs = pd.DataFrame(data,\n",
        "                                     columns=['system_a', \"score_a\", \"zscore_a\", \"system_b\", \"score_b\", \"zscore_b\"])\n",
        "    return df_selected_pairs\n",
        "\n",
        "\n",
        "def select_segment_pairs(df_human_scores, aspect, sentence_id_cols, system_id_cols):\n",
        "    df_scores = df_human_scores.reset_index()\n",
        "    cols_of_interest = system_id_cols + [aspect, f\"{aspect}_zscore\"]\n",
        "    #cols_of_interest = [aspect, f\"{aspect}_zscore\"]\n",
        "    selected_pairs = (df_scores.groupby(sentence_id_cols)[cols_of_interest].apply(_select_pairs_in_group)\n",
        "                                .reset_index(level=1, drop=True)\n",
        "                                .reset_index())\n",
        "    return selected_pairs\n",
        "\n",
        "\n",
        "def compute_relative_ranking_correlations(df_human_scores, df_metrics_scores, aspect,\n",
        "                                          segment_id_cols, sentence_id_cols, system_id_cols,\n",
        "                                          use_absolute_values=True, bootstrap_samples=1000):\n",
        "    df_segment_pairs = select_segment_pairs(df_human_scores, aspect, sentence_id_cols, system_id_cols)\n",
        "\n",
        "    df_all_scores = pd.merge(left=df_segment_pairs,\n",
        "                             left_on=sentence_id_cols+['system_a'],\n",
        "                             right=df_metrics_scores,\n",
        "                             right_on=segment_id_cols)\n",
        "    df_all_scores = pd.merge(left=df_all_scores,\n",
        "                             left_on=sentence_id_cols+['system_b'],\n",
        "                             right=df_metrics_scores,\n",
        "                             right_on=segment_id_cols)\n",
        "\n",
        "    metrics_names = [col for col in df_metrics_scores.columns if col not in segment_id_cols]\n",
        "\n",
        "    # Compute the correlations\n",
        "    print(\"Computing correlations...\")\n",
        "    correlations_data = []\n",
        "    for metric in metrics_names:\n",
        "        #corr = kendall_tau_wmt(df_all_scores[['zscore_a', 'zscore_b', f\"{metric}_x\", f\"{metric}_y\"]])\n",
        "        #corr, pval = spearmanr(df_all_scores[['zscore_a', f\"{metric}_x\"]], df_all_scores[['zscore_b', f\"{metric}_y\"]], axis=None)\n",
        "        corr, pval = spearmanr(df_all_scores[['zscore_a', 'zscore_b']], df_all_scores[[f\"{metric}_x\", f\"{metric}_y\"]], axis=None)\n",
        "        if use_absolute_values:\n",
        "            corr = abs(corr)\n",
        "        correlations_data.append([metric, corr])\n",
        "    df_correlations = pd.DataFrame(correlations_data, columns=['metric', 'corr'])\n",
        "\n",
        "    # Bootstrap sampling\n",
        "    print(\"Bootstrap sampling...\")\n",
        "    correlations_bootstrap_data = []\n",
        "    for _ in range(bootstrap_samples):\n",
        "        df_scores_sample = df_all_scores.sample(n=len(df_all_scores), replace=True)\n",
        "        for metric in metrics_names:\n",
        "            corr_sample = kendall_tau_wmt(df_scores_sample[['zscore_a', 'zscore_b', f\"{metric}_x\", f\"{metric}_y\"]])\n",
        "            if use_absolute_values:\n",
        "                corr_sample = abs(corr_sample)\n",
        "            correlations_bootstrap_data.append([metric, corr_sample])\n",
        "    df_bootstrap_correlations = pd.DataFrame(correlations_bootstrap_data, columns=['metric', 'corr'])\n",
        "\n",
        "    # Compute 95% confidence intervals for each metric\n",
        "    print(\"Computing 95% confidence intervals for each metric...\")\n",
        "    confidence_intervals = []\n",
        "    for metric in metrics_names:\n",
        "        metric_corr = df_bootstrap_correlations[df_bootstrap_correlations['metric'] == metric]['corr']\n",
        "        # Equivalent to using the R function quantile with default type 7\n",
        "        lower, upper = mquantiles(metric_corr, prob=[0.05, 0.95], alphap=1, betap=1)\n",
        "        confidence_intervals.append(pd.Interval(left=lower, right=upper, closed='both'))\n",
        "    df_correlations['conf_interval'] = confidence_intervals\n",
        "    df_correlations.sort_values(by=['corr'], ascending=False, inplace=True, ignore_index=True)\n",
        "\n",
        "    # Determine if the difference in performance is significant\n",
        "    print(\"Determining if the difference in performance is significant...\")\n",
        "    metrics_names = df_correlations['metric'].to_list()\n",
        "    significance_matrix = []\n",
        "    winner_status = []\n",
        "    for _, row_metric_a in df_correlations.iterrows():\n",
        "        metric_a = row_metric_a['metric']\n",
        "        ci_metric_a = row_metric_a['conf_interval']\n",
        "        is_winner = True\n",
        "        significance_row = []\n",
        "        for _, row_metric_b in df_correlations.iterrows():\n",
        "            metric_b = row_metric_b['metric']\n",
        "            ci_metric_b = row_metric_b['conf_interval']\n",
        "            # It's significant if confidence intervals do not overlap\n",
        "            is_diff_stats_significant = ci_metric_a.left > ci_metric_b.right\n",
        "            significance_row.append(is_diff_stats_significant)\n",
        "            # Update winner status (not significantly outperformed by any other metric)\n",
        "            if metric_b != metric_a:\n",
        "                is_winner = is_winner and is_diff_stats_significant\n",
        "        significance_matrix.append(significance_row)\n",
        "        winner_status.append(is_winner)\n",
        "    df_correlations['is_winner'] = winner_status\n",
        "    df_significance = pd.DataFrame(np.array(significance_matrix), columns=metrics_names, index=metrics_names)\n",
        "\n",
        "    return df_correlations, df_significance\n",
        "\n",
        "\n",
        "def kendall_tau_wmt(df_scores):\n",
        "    concordant = 0\n",
        "    discordant = 0\n",
        "    #print(df_scores)\n",
        "    for _, (score_a, score_b, metric_a, metric_b) in df_scores.iterrows():\n",
        "        if score_a < score_b:\n",
        "            if metric_a < metric_b:\n",
        "                concordant += 1\n",
        "            else:\n",
        "                discordant += 1\n",
        "        elif score_a >= score_b:\n",
        "            if metric_a <= metric_b:\n",
        "                discordant += 1\n",
        "            else:\n",
        "                concordant += 1\n",
        "    if (abs(concordant) + abs(discordant)) != 0:\n",
        "        return (abs(concordant) - abs(discordant)) / (abs(concordant) + abs(discordant))\n",
        "    else:\n",
        "        print('concordant: ', concordant)\n",
        "        print('discordant: ', discordant)\n",
        "        print(df_scores)\n",
        "        sys.exit(0)\n",
        "\n",
        "\n",
        "def compute_direct_assessment_correlations(df_human_scores, df_metrics_scores, aspect, segment_id_cols,\n",
        "                                           use_absolute_values=True):\n",
        "    df_da_scores = df_human_scores.reset_index()\n",
        "    cols_of_interest = segment_id_cols + [aspect, f\"{aspect}_zscore\"]\n",
        "    df_da_scores = df_da_scores[cols_of_interest]\n",
        "    df_all_scores = pd.merge(left=df_metrics_scores, right=df_da_scores, on=segment_id_cols)\n",
        "\n",
        "    # Compute correlations metrics vs human scores\n",
        "    print(\"Computing correlations...\")\n",
        "    metrics_names = [col for col in df_metrics_scores.columns if col not in segment_id_cols]\n",
        "    correlations_data = []\n",
        "    for metric in metrics_names:\n",
        "        corr, p_value = pearsonr(df_all_scores[metric], df_all_scores[f'{aspect}_zscore'])\n",
        "        if use_absolute_values:\n",
        "            corr = abs(corr)\n",
        "        correlations_data.append([metric, corr, p_value])\n",
        "    df_correlations_metrics_human = pd.DataFrame(correlations_data, columns=['metric', 'corr', 'p_value'])\n",
        "    df_correlations_metrics_human.sort_values(by=['corr'], ascending=False, inplace=True, ignore_index=True)\n",
        "\n",
        "    # Compute correlations metrics vs metrics\n",
        "    metrics_names = df_correlations_metrics_human['metric'].to_list()\n",
        "    correlations_data = []\n",
        "    for _, (metric_a, corr_metric_a, _) in df_correlations_metrics_human.iterrows():\n",
        "        for _, (metric_b, corr_metric_b, _) in df_correlations_metrics_human.iterrows():\n",
        "            corr_a_b, pvalue_a_b = pearsonr(df_all_scores[metric_a], df_all_scores[metric_b])\n",
        "            if use_absolute_values:\n",
        "                corr_a_b = abs(corr_a_b)\n",
        "            correlations_data.append([metric_a, corr_metric_a,\n",
        "                                      metric_b, corr_metric_b,\n",
        "                                      corr_a_b, pvalue_a_b])\n",
        "    df_correlations_metric_metric = pd.DataFrame(correlations_data,\n",
        "                                                 columns=['metric_a', 'corr_metric_a',\n",
        "                                                          'metric_b', 'corr_metric_b',\n",
        "                                                          'corr_a_b', 'pvalue_a_b'])\n",
        "\n",
        "    # Determine if the difference in performance is significant\n",
        "    print(\"Determining if the difference in performance is significant...\")\n",
        "    significance_matrix = []\n",
        "    winner_status = []\n",
        "    for metric_a in metrics_names:\n",
        "        df_correlations = df_correlations_metric_metric[df_correlations_metric_metric['metric_a'] == metric_a]\n",
        "        is_winner = True\n",
        "        significance_row = []\n",
        "        for _, (_, corr_metric_a, metric_b, corr_metric_b, corr_a_b, _) in df_correlations.iterrows():\n",
        "            p = np.nan\n",
        "            if (metric_a != metric_b) and (corr_metric_a > corr_metric_b):\n",
        "                _, p = williams_test(corr_metric_a, corr_metric_b, corr_a_b, len(df_human_scores))\n",
        "            is_diff_stats_significant = p < 0.05\n",
        "            if not is_diff_stats_significant:\n",
        "                # we do not care about the exact values in cases where it's not significant\n",
        "                p = np.nan\n",
        "            significance_row.append(p)\n",
        "            # Update winner status (not significantly outperformed by any other metric)\n",
        "            if metric_a != metric_b:\n",
        "                is_winner = is_winner and is_diff_stats_significant\n",
        "        significance_matrix.append(significance_row)\n",
        "        winner_status.append(is_winner)\n",
        "    df_correlations_metrics_human['is_winner'] = winner_status\n",
        "    df_significance = pd.DataFrame(np.array(significance_matrix), columns=metrics_names, index=metrics_names)\n",
        "\n",
        "    return df_correlations_metrics_human, df_significance\n",
        "\n",
        "\n",
        "# From https://github.com/inmoonlight/nlp-williams/blob/master/williams.py\n",
        "def williams_test(r12, r13, r23, n):\n",
        "    \"\"\"The Williams test (Evan J. Williams. 1959. Regression Analysis, volume 14. Wiley, New York, USA)\n",
        "    A test of whether the population correlation r12 equals the population correlation r13.\n",
        "    Significant: p < 0.05\n",
        "    Arguments:\n",
        "        r12 (float): correlation between x1, x2\n",
        "        r13 (float): correlation between x1, x3\n",
        "        r23 (float): correlation between x2, x3\n",
        "        n (int): size of the population\n",
        "    Returns:\n",
        "        t (float): Williams test result\n",
        "        p (float): p-value of t-dist\n",
        "    \"\"\"\n",
        "    assert (r12 >= r13), \"r12 should be larger than r13\"\n",
        "    assert (n > 3), \"n should be larger than 3\"\n",
        "\n",
        "    K = 1 - r12 ** 2 - r13 ** 2 - r23 ** 2 + 2 * r12 * r13 * r23\n",
        "    denominator = np.sqrt(\n",
        "        2 * K * (n - 1) / (n - 3) + (((r12 + r13) ** 2) / 4) * ((1 - r23) ** 3)\n",
        "    )\n",
        "    numerator = (r12 - r13) * np.sqrt((n - 1) * (1 + r23))\n",
        "    p = 1 - t.cdf(numerator / denominator, df=n - 3)  # changed to n-3 on 30/11/14\n",
        "    return t, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "oI9i-PHbqWCR",
        "outputId": "dff5b757-d69c-489d-8cb3-66ba4887fc05"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5fda78c96e12>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0measse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTEST_SETS_PATHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0measse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'easse'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from easse.utils.constants import TEST_SETS_PATHS\n",
        "from easse.utils.helpers import read_lines\n",
        "import math\n",
        "import scipy\n",
        "\n",
        "def read_test_set(test_set, as_lists=False):\n",
        "    orig_sents_path = TEST_SETS_PATHS[(test_set, \"orig\")]\n",
        "    refs_sents_paths = TEST_SETS_PATHS[(test_set, \"refs\")]\n",
        "    num_refs = len(refs_sents_paths)\n",
        "\n",
        "    orig_sents = read_lines(orig_sents_path)\n",
        "    refs_sents = [read_lines(ref_sents_path) for ref_sents_path in refs_sents_paths]\n",
        "\n",
        "    if as_lists:\n",
        "        return orig_sents, refs_sents\n",
        "\n",
        "    fhs = [orig_sents] + refs_sents\n",
        "    all_sent_id = []\n",
        "    all_orig_sent = []\n",
        "    all_ref_sents = []\n",
        "    for sent_id, (orig_sent, *ref_sents) in enumerate(zip(*fhs), start=1):\n",
        "        all_sent_id += [sent_id] * num_refs\n",
        "        all_orig_sent += [orig_sent] * num_refs\n",
        "        all_ref_sents += ref_sents\n",
        "    return pd.DataFrame(\n",
        "        list(zip(all_sent_id, all_orig_sent, all_ref_sents)),\n",
        "        columns=[\"sent_id\", \"orig_sent\", \"ref_sent\"],\n",
        "    )\n",
        "\n",
        "\n",
        "def collect_references(sent_ids, test_set_orig_sents, test_set_refs_sents, num_refs):\n",
        "    orig_sents = []\n",
        "    refs_sents = [[] for i in range(num_refs)]\n",
        "    for sent_id in sent_ids:\n",
        "        orig_sents.append(test_set_orig_sents[sent_id-1])\n",
        "        for i, ref in enumerate(test_set_refs_sents):\n",
        "            refs_sents[i].append(ref[sent_id-1])\n",
        "\n",
        "    return orig_sents, refs_sents\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIbp7WTCqb0A"
      },
      "outputs": [],
      "source": [
        "from easse.bleu import corpus_bleu\n",
        "from easse.fkgl import corpus_fkgl\n",
        "from easse.samsa import get_samsa_sentence_scores\n",
        "from easse.sari import corpus_sari\n",
        "#from easse.bertscore import corpus_bertscore\n",
        "from bert_score import BERTScorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ew4arFSOqdgl"
      },
      "outputs": [],
      "source": [
        "asset_orig, asset_refs = read_test_set(\"asset_test\", as_lists=True)\n",
        "turk_orig, turk_refs = read_test_set(\"turkcorpus_test\", as_lists=True)\n",
        "hsplit_orig, hsplit_refs = read_test_set(\"hsplit_test\", as_lists=True)\n",
        "\n",
        "# We create a dataset composed of all references together\n",
        "all_orig = asset_orig\n",
        "all_refs = asset_refs + turk_refs + hsplit_refs\n",
        "\n",
        "EVAL_DATASETS = {\n",
        "    \"asset\": (asset_orig, asset_refs, 10),  # (original, references, number of references)\n",
        "    #\"turk\": (turk_orig, turk_refs, 8),\n",
        "    #\"hsplit\": (hsplit_orig, hsplit_refs, 4),\n",
        "    #\"all\": (all_orig, all_refs, 22)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79PwUqYSZAkR"
      },
      "source": [
        "# make human-written data as the same format of simplicity-DA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J3gC_pxem44"
      },
      "outputs": [],
      "source": [
        "def standardise_ratings(df, rater_id, aspect):\n",
        "    return df.groupby(by=rater_id)[aspect].transform(lambda x: zscore(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMaWW63Sefow",
        "outputId": "1f801bbd-ae98-4f67-fcd6-52756e26357c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-5fae8518b660>:17: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  df_hg_all_grouped = df_hg_all.groupby(['sentence_id']).mean()\n"
          ]
        }
      ],
      "source": [
        "df_hg = pd.read_csv(\"./src/simplification_human_evaluations/questeval_simplification_likert_ratings.csv\")\n",
        "df_hg = df_hg[df_hg['simplification_type'] == 'human']\n",
        "simplicity_zscore = standardise_ratings(df_hg[df_hg['aspect'] == 'simplicity'], rater_id='worker_id', aspect=\"rating\")\n",
        "meaning_zscore = standardise_ratings(df_hg[df_hg['aspect'] == 'meaning'], rater_id='worker_id', aspect=\"rating\")\n",
        "fluency_zscore = standardise_ratings(df_hg[df_hg['aspect'] == 'fluency'], rater_id='worker_id', aspect=\"rating\")\n",
        "df_hg_simp = df_hg[df_hg['aspect'] == 'simplicity'].copy().drop(columns=['aspect', 'rating'])\n",
        "df_hg_simp['simplicity_zscore'] = simplicity_zscore\n",
        "df_hg_simp['simplicity'] = df_hg[df_hg['aspect'] == 'simplicity']['rating']\n",
        "df_hg_mean = df_hg[df_hg['aspect'] == 'meaning'].copy().drop(columns=['aspect', 'rating'])\n",
        "df_hg_mean['meaning_zscore'] = meaning_zscore\n",
        "df_hg_mean['meaning'] = df_hg[df_hg['aspect'] == 'meaning']['rating']\n",
        "df_hg_flu = df_hg[df_hg['aspect'] == 'fluency'].copy().drop(columns=['aspect', 'rating'])\n",
        "df_hg_flu['fluency_zscore'] = fluency_zscore\n",
        "df_hg_flu['fluency'] = df_hg[df_hg['aspect'] == 'fluency']['rating']\n",
        "df_hg_all = df_hg_simp.merge(df_hg_mean, on=['source', 'simplification', 'sentence_id', 'simplification_type', 'system_name', 'worker_id', 'references'])\n",
        "df_hg_all = df_hg_all.merge(df_hg_flu, on=['source', 'simplification', 'sentence_id', 'simplification_type', 'system_name', 'worker_id', 'references'])\n",
        "df_hg_all_grouped = df_hg_all.groupby(['sentence_id']).mean()\n",
        "#df_hg_all_grouped['sentence_id'] = df_hg_all_grouped['sentence_id'].astype(int)\n",
        "#df_hg_all_grouped['sentence_id'] = df_hg_all_grouped.index\n",
        "df_hg_all_grouped.reset_index(inplace=True)\n",
        "df_hg_all_ddup = df_hg_all.drop_duplicates(subset='sentence_id')\n",
        "df_hg_all_grouped = df_hg_all_grouped.merge(df_hg_all_ddup.drop(columns=['worker_id', 'simplicity_zscore', 'meaning_zscore', 'fluency_zscore', 'simplicity', 'fluency', 'meaning']), on=['sentence_id'])\n",
        "df_hg_all_grouped.rename(columns={'sentence_id': 'sent_id', 'system_name': 'sys_name', 'source': 'orig_sent', 'simplification': 'simp_sent'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVc-5sNw5b7H",
        "outputId": "2d19a2fb-fdb3-4140-ba74-f72e719298dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Since 2000, the recipient of the Kate Greenaway Medal has also won the £5000 Colin Mears Award.',\n",
              " 'Since 2000, the winner of the Kate Greenaway Medal also receives the Colin Mears Award.  The value of the prize is £5000.',\n",
              " 'Since 2000, the person that receives the Kate Greenaway Medal has also been presented with the Colin Mears Award that has a value of £5000.',\n",
              " 'Since 2000, the Kate Greenaway Medal winner has also been presented with the Colin Mears Award, valued £5000.',\n",
              " 'Since 2000, the winner of the Kate Greenaway Medal won the  Colin Mears Award to the value of £5000.',\n",
              " 'Whoever wins the Kate Greenway Medal also gets The Colin Mears award which is L5000.',\n",
              " 'Since 2000, the recipient of the Kate Greenaway Medal will also receive the Colin Mears Awad which worth 5000 pounds.',\n",
              " 'Since 2000, the recipient of the Kate Greenaway Medal has also been given the Colin Mears Award.',\n",
              " 'The winner of the Kate Greenaway Medal has also been given the Colin Mears Award (valued at £5000) since the year 2000.',\n",
              " 'Many people who receive the Kate Greenaway Medal also win the Colin Mears Award. Its worth £5000.']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "eval(df_hg_all_grouped.iloc[0]['references']) # attached references are from ASSET, because # of references is 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmp5pwF8ZRpm"
      },
      "source": [
        "# get df_metrics_segment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB8jmKzfax8N"
      },
      "outputs": [],
      "source": [
        "lowercase = False  # case-insensitive\n",
        "tokenizer = \"moses\"\n",
        "bertscore_rescale = BERTScorer(lang=\"en\", rescale_with_baseline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJKhZi2xZcZQ"
      },
      "outputs": [],
      "source": [
        "df_hg_all_grouped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-VSBstda8W4"
      },
      "outputs": [],
      "source": [
        "for _, row in tqdm(df_hg_all_grouped.iterrows()):\n",
        "    orig_sents = [row['source']]\n",
        "    ref_sents = [[i] for i in eval(row['references'])]\n",
        "    simp_sents = [row['simplification']]\n",
        "    print(orig_sents)\n",
        "    print(ref_sents)\n",
        "    print(simp_sents)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOHLH1zH9sHr"
      },
      "outputs": [],
      "source": [
        "metrics = []\n",
        "test_set = \"asset\"\n",
        "for _, row in tqdm(df_hg_all_grouped.iterrows()):\n",
        "    orig_sents = [row['orig_sent']]\n",
        "    ref_sents = [[i] for i in eval(row['references'])]\n",
        "    simp_sents = [row['simp_sent']]\n",
        "\n",
        "    # BLEU\n",
        "    bleu_sys_refs = corpus_bleu(\n",
        "        [row[\"simp_sent\"]],\n",
        "        ref_sents,\n",
        "        smooth_method=\"floor\",\n",
        "        tokenizer=tokenizer,\n",
        "        lowercase=lowercase,\n",
        "        effective_order=True,\n",
        "    )\n",
        "\n",
        "    # SARI\n",
        "    sari_score = corpus_sari(\n",
        "        orig_sents,\n",
        "        [row[\"simp_sent\"]],\n",
        "        ref_sents,\n",
        "        tokenizer=tokenizer,\n",
        "        lowercase=lowercase,\n",
        "        use_f1_for_deletion=False,\n",
        "    )\n",
        "\n",
        "    # # iBLEU (alpha = 0.9)\n",
        "    # bleu_sys_orig = corpus_bleu(\n",
        "    #     [row[\"simp_sent\"]],\n",
        "    #     [orig_sents],\n",
        "    #     force=True,\n",
        "    #     tokenizer=tokenizer,\n",
        "    #     lowercase=lowercase,\n",
        "    # )\n",
        "    # ibleu_score = 0.9 * bleu_sys_refs - (1 - 0.9) * bleu_sys_orig\n",
        "\n",
        "    # # Avg. of BLEU and SARI\n",
        "    # amean_bleu_sari = np.mean([bleu_sys_refs, sari_score])\n",
        "    # gmean_bleu_sari = scipy.stats.gmean([bleu_sys_refs, sari_score])\n",
        "\n",
        "    # Flesch\n",
        "    fkgl_sys = corpus_fkgl([row[\"simp_sent\"]], tokenizer=tokenizer)\n",
        "\n",
        "    # # FKBLEU\n",
        "    # fkgl_orig = corpus_fkgl(orig_sents, tokenizer=tokenizer)\n",
        "    # fk_diff = sigmoid(fkgl_sys - fkgl_orig)\n",
        "    # fkbleu_score = ibleu_score * fk_diff\n",
        "\n",
        "    # BERTScore\n",
        "    ref_sents = [ref for [ref] in ref_sents]\n",
        "    bertscore_rescale_scores = bertscore_rescale.score([row[\"simp_sent\"]], [ref_sents])\n",
        "    #bertscores = corpus_bertscore([\n",
        "    #    row[\"simp_sent\"]],\n",
        "    #    ref_sents,\n",
        "    #    tokenizer=tokenizer,\n",
        "    #    lowercase=lowercase\n",
        "    #)\n",
        "\n",
        "    metrics.append(\n",
        "        {\n",
        "            \"sent_id\": row[\"sent_id\"],\n",
        "            \"sys_name\": row[\"sys_name\"],\n",
        "            \"test_set\": test_set,\n",
        "            \"bleu\": bleu_sys_refs,\n",
        "            \"sari\": sari_score,\n",
        "            \"ibleu\": ibleu_score,\n",
        "            \"amean_bleu_sari\": amean_bleu_sari,\n",
        "            \"gmean_bleu_sari\": gmean_bleu_sari,\n",
        "            \"fkgl\": fkgl_sys,\n",
        "            \"fkbleu\": fkbleu_score,\n",
        "            \"bertscore_P\": bertscore_rescale_scores[0].cpu().item(),\n",
        "            \"bertscore_R\": bertscore_rescale_scores[1].cpu().item(),\n",
        "            \"bertscore_F1\": bertscore_rescale_scores[2].cpu().item(),\n",
        "            #\"bertscore_P\": bertscores[0],\n",
        "            #\"bertscore_R\": bertscores[1],\n",
        "            #\"bertscore_F1\": bertscores[2],\n",
        "        }\n",
        "    )\n",
        "\n",
        "df_metrics_segment = pd.DataFrame(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_p49FJ5pK0c"
      },
      "outputs": [],
      "source": [
        "samsa_scores = get_samsa_sentence_scores(\n",
        "    df_hg_all_grouped[\"orig_sent\"],\n",
        "    df_hg_all_grouped[\"simp_sent\"],\n",
        "    tokenizer=tokenizer,\n",
        "    lowercase=lowercase,\n",
        ")\n",
        "\n",
        "# Since SAMSA is reference-less, this reformating is only done so that it can appear in thae same dataframe as the other metrics\n",
        "df_metrics_segment[\"samsa\"] = [\n",
        "    s for s in samsa_scores for _ in range(len(EVAL_DATASETS))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVNzm4FeD3JD"
      },
      "outputs": [],
      "source": [
        "df_metrics_segment['amean_bleu_samsa'] = np.mean(df_metrics_segment[['bleu', 'samsa']], axis=1)\n",
        "df_metrics_segment['amean_sari_samsa'] = np.mean(df_metrics_segment[['sari', 'samsa']], axis=1)\n",
        "df_metrics_segment['gmean_bleu_samsa'] = scipy.stats.gmean(df_metrics_segment[['bleu', 'samsa']], axis=1)\n",
        "df_metrics_segment['gmean_sari_samsa'] = scipy.stats.gmean(df_metrics_segment[['sari', 'samsa']], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHfhmHl8oU2q"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('./src/simplification_human_evaluations/df_metrics_segment_hg.pickle', 'wb') as f:\n",
        "    pickle.dump(df_metrics_segment, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPeRvjOcpMOx"
      },
      "source": [
        "# compute correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpwE7-s3pYP8"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('./src/simplification_human_evaluations/df_metrics_segment_hg.pickle', 'rb') as f:\n",
        "    df_metrics_segment = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxzh9rlej2VA"
      },
      "source": [
        "## direct assessment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC8sBo4Epi1v"
      },
      "outputs": [],
      "source": [
        "def compute_direct_correlations(df_benchmark, df_segment_metrics, aspects, test_sets, segment_id_cols):\n",
        "    results = {}\n",
        "    for aspect in aspects:\n",
        "        smed = df_benchmark['simplicity_zscore'].median()\n",
        "        shind = df_benchmark['simplicity_zscore'] > smed\n",
        "        slind = df_benchmark['simplicity_zscore'] <= smed\n",
        "        fmed = df_benchmark['fluency_zscore'].median()\n",
        "        fhind = df_benchmark['fluency_zscore'] > fmed\n",
        "        flind = df_benchmark['fluency_zscore'] <= fmed\n",
        "        mmed = df_benchmark['meaning_zscore'].median()\n",
        "        mhind = df_benchmark['meaning_zscore'] > mmed\n",
        "        mlind = df_benchmark['meaning_zscore'] <= mmed\n",
        "        fmhind = (df_benchmark['fluency_zscore'] > fmed) & (df_benchmark['meaning_zscore'] > mmed)\n",
        "        fmlind = (df_benchmark['fluency_zscore'] <= fmed) & (df_benchmark['meaning_zscore'] <= mmed)\n",
        "        df_scores_slow = df_benchmark[slind]\n",
        "        df_scores_shigh = df_benchmark[shind]\n",
        "        df_scores_flow = df_benchmark[flind]\n",
        "        df_scores_fhigh = df_benchmark[fhind]\n",
        "        df_scores_mlow = df_benchmark[mlind]\n",
        "        df_scores_mhigh = df_benchmark[mhind]\n",
        "        df_scores_fmlow = df_benchmark[fmlind]\n",
        "        df_scores_fmhigh = df_benchmark[fmhind]\n",
        "\n",
        "        print(f\"{aspect}: simp_high ({len(df_scores_shigh)}) - simp_low ({len(df_scores_slow)}) - flu_low ({len(df_scores_flow)}) - flu_high ({len(df_scores_fhigh)}) - mean_low ({len(df_scores_mlow)}) - mean_high ({len(df_scores_mhigh)}) - fm_low ({len(df_scores_fmlow)}) - fm_high ({len(df_scores_fmhigh)}) - All ({len(df_benchmark)})\")\n",
        "        for quality, df_scores in {'simp_low': df_scores_slow, 'simp_high': df_scores_shigh, 'flu_low': df_scores_flow, 'flu_high': df_scores_fhigh, 'mean_low': df_scores_mlow, 'mean_high': df_scores_mhigh, 'fm_low': df_scores_fmlow, 'fm_high': df_scores_fmhigh, 'all': df_benchmark}.items():\n",
        "            for test_set in test_sets:\n",
        "                print(f\"Computing for {quality} scores - {test_set} references\")\n",
        "                df_metrics = df_segment_metrics[df_segment_metrics.test_set==test_set].drop(columns=['test_set'])\n",
        "                results[(quality, aspect, test_set)] = compute_direct_assessment_correlations(\n",
        "                    df_scores,\n",
        "                    df_metrics,\n",
        "                    aspect,\n",
        "                    segment_id_cols=segment_id_cols,\n",
        "                    use_absolute_values=False\n",
        "                )\n",
        "                print()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8OYhzhopnaJ"
      },
      "outputs": [],
      "source": [
        "METRICS_TO_ANALYSE = ['bleu', 'sari', 'fkgl', 'fkbleu', 'ibleu',\n",
        "                      'amean_bleu_sari',\n",
        "                      'gmean_bleu_sari',\n",
        "                      'bertscore_P', 'bertscore_R', 'bertscore_F1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b-5Y1RiPNjF"
      },
      "outputs": [],
      "source": [
        "EVAL_DATASETS = ['asset']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5BoG9yyqJ4u"
      },
      "outputs": [],
      "source": [
        "df_hg_all_grouped.rename(columns={'sentence_id': 'sent_id', 'system_name': 'sys_name'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rENe5Om0p6Za",
        "outputId": "aae78f97-c598-4bf2-84cb-b07895c79d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simplicity: simp_high (50) - simp_low (50) - flu_low (50) - flu_high (50) - mean_low (50) - mean_high (50) - fm_low (35) - fm_high (35) - All (100)\n",
            "Computing for simp_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for simp_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for flu_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for flu_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for mean_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for mean_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for fm_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for fm_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for all scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_simplicity = compute_direct_correlations(\n",
        "                        df_hg_all_grouped,\n",
        "                        df_metrics_segment,\n",
        "                        aspects=['simplicity'],\n",
        "                        test_sets=EVAL_DATASETS,\n",
        "                        segment_id_cols=['sent_id','sys_name']\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "FObtshwV_hAa",
        "outputId": "ed862da7-ca73-4cb3-f2bb-cae0024bc4cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c3546b82-3ee2-4ce8-9110-834118c21214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>corr</th>\n",
              "      <th>p_value</th>\n",
              "      <th>is_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bertscore_P</td>\n",
              "      <td>0.417633</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gmean_bleu_sari</td>\n",
              "      <td>0.415641</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amean_bleu_sari</td>\n",
              "      <td>0.407919</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ibleu</td>\n",
              "      <td>0.396765</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bertscore_F1</td>\n",
              "      <td>0.393838</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sari</td>\n",
              "      <td>0.390478</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bertscore_R</td>\n",
              "      <td>0.374249</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bleu</td>\n",
              "      <td>0.349962</td>\n",
              "      <td>0.000358</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fkbleu</td>\n",
              "      <td>-0.146599</td>\n",
              "      <td>0.145549</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fkgl</td>\n",
              "      <td>-0.353133</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3546b82-3ee2-4ce8-9110-834118c21214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3546b82-3ee2-4ce8-9110-834118c21214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3546b82-3ee2-4ce8-9110-834118c21214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-42e4dbee-0629-4bce-be1c-8782c9a5f9d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42e4dbee-0629-4bce-be1c-8782c9a5f9d1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-42e4dbee-0629-4bce-be1c-8782c9a5f9d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            metric      corr   p_value  is_winner\n",
              "0      bertscore_P  0.417633  0.000015      False\n",
              "1  gmean_bleu_sari  0.415641  0.000017      False\n",
              "2  amean_bleu_sari  0.407919  0.000025      False\n",
              "3            ibleu  0.396765  0.000044      False\n",
              "4     bertscore_F1  0.393838  0.000050      False\n",
              "5             sari  0.390478  0.000059      False\n",
              "6      bertscore_R  0.374249  0.000125      False\n",
              "7             bleu  0.349962  0.000358      False\n",
              "8           fkbleu -0.146599  0.145549      False\n",
              "9             fkgl -0.353133  0.000314      False"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_simplicity[('all', 'simplicity', 'asset')][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjgCwE8gjv8K"
      },
      "source": [
        "## relative ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wrhu-WSZxrS5"
      },
      "outputs": [],
      "source": [
        "def compute_relative_ranking_correlations(df_human_scores, df_metrics_scores, aspect, segment_id_cols,\n",
        "                                           use_absolute_values=True):\n",
        "    df_da_scores = df_human_scores.reset_index()\n",
        "    cols_of_interest = segment_id_cols + [aspect, f\"{aspect}_zscore\"]\n",
        "    df_da_scores = df_da_scores[cols_of_interest]\n",
        "    df_all_scores = pd.merge(left=df_metrics_scores, right=df_da_scores, on=segment_id_cols)\n",
        "\n",
        "    # Compute correlations metrics vs human scores\n",
        "    print(\"Computing correlations...\")\n",
        "    metrics_names = [col for col in df_metrics_scores.columns if col not in segment_id_cols]\n",
        "    correlations_data = []\n",
        "    for metric in metrics_names:\n",
        "        corr, p_value = spearmanr(df_all_scores[metric], df_all_scores[f'{aspect}_zscore'])\n",
        "        if use_absolute_values:\n",
        "            corr = abs(corr)\n",
        "        correlations_data.append([metric, corr, p_value])\n",
        "    df_correlations_metrics_human = pd.DataFrame(correlations_data, columns=['metric', 'corr', 'p_value'])\n",
        "    df_correlations_metrics_human.sort_values(by=['corr'], ascending=False, inplace=True, ignore_index=True)\n",
        "\n",
        "    # Compute correlations metrics vs metrics\n",
        "    metrics_names = df_correlations_metrics_human['metric'].to_list()\n",
        "    correlations_data = []\n",
        "    for _, (metric_a, corr_metric_a, _) in df_correlations_metrics_human.iterrows():\n",
        "        for _, (metric_b, corr_metric_b, _) in df_correlations_metrics_human.iterrows():\n",
        "            corr_a_b, pvalue_a_b = pearsonr(df_all_scores[metric_a], df_all_scores[metric_b])\n",
        "            if use_absolute_values:\n",
        "                corr_a_b = abs(corr_a_b)\n",
        "            correlations_data.append([metric_a, corr_metric_a,\n",
        "                                      metric_b, corr_metric_b,\n",
        "                                      corr_a_b, pvalue_a_b])\n",
        "    df_correlations_metric_metric = pd.DataFrame(correlations_data,\n",
        "                                                 columns=['metric_a', 'corr_metric_a',\n",
        "                                                          'metric_b', 'corr_metric_b',\n",
        "                                                          'corr_a_b', 'pvalue_a_b'])\n",
        "\n",
        "    # Determine if the difference in performance is significant\n",
        "    print(\"Determining if the difference in performance is significant...\")\n",
        "    significance_matrix = []\n",
        "    winner_status = []\n",
        "    for metric_a in metrics_names:\n",
        "        df_correlations = df_correlations_metric_metric[df_correlations_metric_metric['metric_a'] == metric_a]\n",
        "        is_winner = True\n",
        "        significance_row = []\n",
        "        for _, (_, corr_metric_a, metric_b, corr_metric_b, corr_a_b, _) in df_correlations.iterrows():\n",
        "            p = np.nan\n",
        "            if (metric_a != metric_b) and (corr_metric_a > corr_metric_b):\n",
        "                _, p = williams_test(corr_metric_a, corr_metric_b, corr_a_b, len(df_human_scores))\n",
        "            is_diff_stats_significant = p < 0.05\n",
        "            if not is_diff_stats_significant:\n",
        "                # we do not care about the exact values in cases where it's not significant\n",
        "                p = np.nan\n",
        "            significance_row.append(p)\n",
        "            # Update winner status (not significantly outperformed by any other metric)\n",
        "            if metric_a != metric_b:\n",
        "                is_winner = is_winner and is_diff_stats_significant\n",
        "        significance_matrix.append(significance_row)\n",
        "        winner_status.append(is_winner)\n",
        "    df_correlations_metrics_human['is_winner'] = winner_status\n",
        "    df_significance = pd.DataFrame(np.array(significance_matrix), columns=metrics_names, index=metrics_names)\n",
        "\n",
        "    return df_correlations_metrics_human, df_significance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYVJGVre33E"
      },
      "outputs": [],
      "source": [
        "def compute_ranking_correlations(df_benchmark, df_segment_metrics, aspects, test_sets, segment_id_cols):\n",
        "    results = {}\n",
        "    for aspect in aspects:\n",
        "        smed = df_benchmark['simplicity_zscore'].median()\n",
        "        shind = df_benchmark['simplicity_zscore'] > smed\n",
        "        slind = df_benchmark['simplicity_zscore'] <= smed\n",
        "        fmed = df_benchmark['fluency_zscore'].median()\n",
        "        fhind = df_benchmark['fluency_zscore'] > fmed\n",
        "        flind = df_benchmark['fluency_zscore'] <= fmed\n",
        "        mmed = df_benchmark['meaning_zscore'].median()\n",
        "        mhind = df_benchmark['meaning_zscore'] > mmed\n",
        "        mlind = df_benchmark['meaning_zscore'] <= mmed\n",
        "        fmhind = (df_benchmark['fluency_zscore'] > fmed) & (df_benchmark['meaning_zscore'] > mmed)\n",
        "        fmlind = (df_benchmark['fluency_zscore'] <= fmed) & (df_benchmark['meaning_zscore'] <= mmed)\n",
        "        df_scores_slow = df_benchmark[slind]\n",
        "        df_scores_shigh = df_benchmark[shind]\n",
        "        df_scores_flow = df_benchmark[flind]\n",
        "        df_scores_fhigh = df_benchmark[fhind]\n",
        "        df_scores_mlow = df_benchmark[mlind]\n",
        "        df_scores_mhigh = df_benchmark[mhind]\n",
        "        df_scores_fmlow = df_benchmark[fmlind]\n",
        "        df_scores_fmhigh = df_benchmark[fmhind]\n",
        "\n",
        "        print(f\"{aspect}: simp_high ({len(df_scores_shigh)}) - simp_low ({len(df_scores_slow)}) - flu_low ({len(df_scores_flow)}) - flu_high ({len(df_scores_fhigh)}) - mean_low ({len(df_scores_mlow)}) - mean_high ({len(df_scores_mhigh)}) - fm_low ({len(df_scores_fmlow)}) - fm_high ({len(df_scores_fmhigh)}) - All ({len(df_benchmark)})\")\n",
        "        for quality, df_scores in {'simp_low': df_scores_slow, 'simp_high': df_scores_shigh, 'flu_low': df_scores_flow, 'flu_high': df_scores_fhigh, 'mean_low': df_scores_mlow, 'mean_high': df_scores_mhigh, 'fm_low': df_scores_fmlow, 'fm_high': df_scores_fmhigh, 'all': df_benchmark}.items():\n",
        "            for test_set in test_sets:\n",
        "                print(f\"Computing for {quality} scores - {test_set} references\")\n",
        "                df_metrics = df_segment_metrics[df_segment_metrics.test_set==test_set].drop(columns=['test_set'])\n",
        "                results[(quality, aspect, test_set)] = compute_relative_ranking_correlations(\n",
        "                    df_human_scores=df_scores,\n",
        "                    df_metrics_scores=df_metrics,\n",
        "                    aspect=aspect,\n",
        "                    segment_id_cols=segment_id_cols,\n",
        "                    #sentence_id_cols=['sent_id'],\n",
        "                    #system_id_cols=['sys_name'],\n",
        "                    use_absolute_values=False,\n",
        "                )\n",
        "                print()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RV6QILRf3fj"
      },
      "outputs": [],
      "source": [
        "METRICS_TO_ANALYSE = ['bleu', 'sari', 'fkgl', 'fkbleu', 'ibleu',\n",
        "                      'amean_bleu_sari',\n",
        "                      'gmean_bleu_sari',\n",
        "                      'bertscore_P', 'bertscore_R', 'bertscore_F1']\n",
        "EVAL_DATASETS = ['asset']\n",
        "df_hg_all_grouped.rename(columns={'sentence_id': 'sent_id', 'system_name': 'sys_name'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VDbSwL2f5Oz",
        "outputId": "472e9830-d8d0-4915-c0ec-3b2af3aa8837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simplicity: simp_high (50) - simp_low (50) - flu_low (50) - flu_high (50) - mean_low (50) - mean_high (50) - fm_low (35) - fm_high (35) - All (100)\n",
            "Computing for simp_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for simp_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for flu_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for flu_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for mean_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for mean_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for fm_low scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for fm_high scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n",
            "Computing for all scores - asset references\n",
            "Computing correlations...\n",
            "Determining if the difference in performance is significant...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results_simplicity = compute_ranking_correlations(\n",
        "                        df_hg_all_grouped,\n",
        "                        df_metrics_segment,\n",
        "                        aspects=['simplicity'],\n",
        "                        test_sets=['asset'],\n",
        "                        segment_id_cols=['sent_id','sys_name']\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5cixc6C7kMit",
        "outputId": "3d67af77-b0fc-44f6-d8ef-2ec586cb5dc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1269e4d1-0945-4299-ba3a-74ed636ad35a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>corr</th>\n",
              "      <th>p_value</th>\n",
              "      <th>is_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bertscore_R</td>\n",
              "      <td>0.401587</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bertscore_F1</td>\n",
              "      <td>0.393353</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gmean_bleu_sari</td>\n",
              "      <td>0.391011</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bertscore_P</td>\n",
              "      <td>0.387352</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>amean_bleu_sari</td>\n",
              "      <td>0.385191</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sari</td>\n",
              "      <td>0.373777</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ibleu</td>\n",
              "      <td>0.346307</td>\n",
              "      <td>0.000417</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bleu</td>\n",
              "      <td>0.312440</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fkbleu</td>\n",
              "      <td>-0.299862</td>\n",
              "      <td>0.002438</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fkgl</td>\n",
              "      <td>-0.359319</td>\n",
              "      <td>0.000241</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1269e4d1-0945-4299-ba3a-74ed636ad35a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1269e4d1-0945-4299-ba3a-74ed636ad35a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1269e4d1-0945-4299-ba3a-74ed636ad35a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9188e2f-6055-4ba0-a241-8fd7300c1ff2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9188e2f-6055-4ba0-a241-8fd7300c1ff2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9188e2f-6055-4ba0-a241-8fd7300c1ff2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            metric      corr   p_value  is_winner\n",
              "0      bertscore_R  0.401587  0.000035      False\n",
              "1     bertscore_F1  0.393353  0.000052      False\n",
              "2  gmean_bleu_sari  0.391011  0.000058      False\n",
              "3      bertscore_P  0.387352  0.000069      False\n",
              "4  amean_bleu_sari  0.385191  0.000076      False\n",
              "5             sari  0.373777  0.000128      False\n",
              "6            ibleu  0.346307  0.000417      False\n",
              "7             bleu  0.312440  0.001552      False\n",
              "8           fkbleu -0.299862  0.002438      False\n",
              "9             fkgl -0.359319  0.000241      False"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_simplicity[('all', 'simplicity', 'asset')][0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SeVNZJF3Y-hy",
        "79PwUqYSZAkR",
        "Bxzh9rlej2VA",
        "WjgCwE8gjv8K"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
